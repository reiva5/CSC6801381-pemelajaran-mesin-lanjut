{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.9"
    },
    "colab": {
      "name": "Tugas3_Jehian Norman Saviero_2006609645.ipynb",
      "provenance": []
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yd7Tu89UXts8"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import random\n",
        "import tensorflow as tf\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from skimage import color, exposure, filters, io, morphology, util\n",
        "from math import sqrt\n",
        "from numpy import loadtxt\n",
        "from tensorflow import keras\n",
        "from keras import backend as K\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D, Dense, Dropout, Flatten, MaxPooling2D, Reshape\n",
        "from keras.optimizers import SGD"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVPkBzPOY3nD"
      },
      "source": [
        "### TRANSFER LEARNING"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-8f0GynyY9PB"
      },
      "source": [
        "1. Bangun sebuah model $\\text{Convolutional Neural Network}$ dengan arsitektur dasar sebagai berikut :\n",
        "    - Convolutional Layer ($25$ maps, kernel $3 \\times 3$)\n",
        "    - Pooling Layer ($2 \\times 2$)\n",
        "    - Activation Function ($\\text{ReLU function}$)\n",
        "    - Convolutional Layer ($50$ maps, kernel $3 \\times 3$)\n",
        "    - Pooling Layer ($2 \\times 2$)\n",
        "    - Activation Function ($\\text{ReLU function}$)\n",
        "    - Convolutional Layer ($100$ maps, kernel $3 \\times 3$)\n",
        "    - Pooling Layer ($2 \\times 2$)\n",
        "    - Activation Function ($\\text{ReLU function}$)\n",
        "    - Hidden Layer ($100$ neuron)\n",
        "    - Activation Function ($\\text{ReLU function}$)\n",
        "    - Output Layer ($10$ kelas)\n",
        "    - Activation Function ($\\text{Softmax function}$)\n",
        "    - Classification Result\n",
        "\n",
        "  Dengan tambahan beberapa seperti:\n",
        "  - Adam optimization\n",
        "  - Early Stop\n",
        "\n",
        "2. Implementasi model $\\text{Convolutional Neural Network}$ tersebut pada dataset $\\text{CIFAR 10}$ (ambil random hanya $1000$ citra per kelas) dengan inisial $\\text{epoch} = 100$, $\\text{batch number} = 10$, $\\text{learning rate} = 0.1$, serta ratio data train dan data test sebanyak $60\\% : 40\\%$."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cRBOHdoNZwid"
      },
      "source": [
        "#### Mendefinisikan Fungsi Bantuan\n",
        "Untuk memudahkan implementasi, berikut beberapa fungsi bantuan yang akan dipakai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pu-1-wDXZ510"
      },
      "source": [
        "##### Menghitung $\\text{recall}$ atau $\\text{sensitivity}$\n",
        "$$\\text{recall} = \\frac{t_p}{t_p+t_n}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "73L3Si5GY8Bt"
      },
      "source": [
        "def recall(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
        "    return true_positives / (possible_positives + K.epsilon())"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vX56S8usaHok"
      },
      "source": [
        "##### Menghitung $\\text{precision}$\n",
        "$$\\text{precision} = \\frac{t_p}{t_p + f_p}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b5R5nRHBaFxN"
      },
      "source": [
        "def precision(y_true, y_pred):\n",
        "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
        "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
        "    return true_positives / (predicted_positives + K.epsilon())"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lSQF6ujjaR3u"
      },
      "source": [
        "##### Menghitung $\\text{specificity}$\n",
        "$$\\text{specificity} = \\frac{t_n}{t_n + f_p}$$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HFNI1C0faMmF"
      },
      "source": [
        "def specificity(y_true, y_pred):\n",
        "    true_negatives = K.sum(K.round(K.clip((1 - y_true) * (1 - y_pred), 0, 1)))\n",
        "    possible_negatives = K.sum(K.round(K.clip(1 - y_true, 0, 1)))\n",
        "    return true_negatives / (possible_negatives + K.epsilon())"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mTOySqnYaXMi"
      },
      "source": [
        "##### Menghitung $f_{1}\\text{ Score}$\n",
        "Kita tau bahwa\n",
        "$$f_{\\beta} = (1 + \\beta^{2}) \\cdot \\frac{\\text{precision} \\cdot \\text{recall}}{(\\beta^{2} \\cdot \\text{precision}) + \\text{recall}}$$\n",
        "Sehingga \n",
        "$$f_{1} = (1 + 1^{2}) \\cdot \\frac{\\text{precision} \\cdot \\text{recall}}{(1^{2} \\cdot \\text{precision}) + \\text{recall}}$$\n",
        "$$f_{1} = (2) \\cdot \\frac{\\text{precision} \\cdot \\text{recall}}{(\\text{precision}) + \\text{recall}}$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g29c08UWaVCZ"
      },
      "source": [
        "def f1_score(y_true, y_pred):\n",
        "    precision_val = precision(y_true, y_pred)\n",
        "    recall_val = recall(y_true, y_pred)\n",
        "    return 2*((precision_val * recall_val)/(precision_val + recall_val + K.epsilon()))"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SJVCS5Q1aldQ"
      },
      "source": [
        "**n.b.: Semua fungsi pada bagian penyebut ditambah epsilon untuk menghindari dibagi $0$ dikarenakan memasukkan input sebanyak $0$**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RJIOkA-caojX"
      },
      "source": [
        "##### Fungsi Bantuan untuk Melakukan Prediksi dan Menampilkan Metric"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PvFKE3jVagwj"
      },
      "source": [
        "def predict_and_get_metrics(model, x_test, y_test, label):\n",
        "    _, accuracy, sensitivity, specificity, score_f1 = model.evaluate(x_test, y_test, verbose=0)\n",
        "    return pd.DataFrame([[accuracy, sensitivity, specificity, score_f1]], columns=['Accuracy', 'Sensitivity', 'Specificity', 'F1 Score'], index=[label])\n",
        "\n",
        "def compare_train_and_test(model, x_train, y_train, x_test, y_test, extra_label=''):\n",
        "    metric_train = predict_and_get_metrics(model, x_train, y_train, 'Data Train %s' % (extra_label))\n",
        "    metric_test = predict_and_get_metrics(model, x_test, y_test, 'Data Test %s' % (extra_label))\n",
        "    return pd.concat([metric_train, metric_test])"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E50lSCtWaxaP"
      },
      "source": [
        "##### Fungsi Bantuan untuk _Load Dataset_"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VRGsFnONasAe"
      },
      "source": [
        "def load_dataset_cifar10():\n",
        "\t(trainX, trainY), (testX, testY) = keras.datasets.cifar10.load_data()\n",
        "\treturn np.concatenate((trainX, testX), axis=0), np.concatenate((trainY, testY), axis=0)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S2YPie55cC8B"
      },
      "source": [
        "#### Load Dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "De3BijFyavrp",
        "outputId": "cb0b4bcb-48a1-4367-89a8-0d2b58c92b31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        }
      },
      "source": [
        "x, y = load_dataset_cifar10()\n",
        "x.shape"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 11s 0us/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(60000, 32, 32, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ol1gGZn1tXcU"
      },
      "source": [
        "#### Mengambil Dataset Sebanyak 1000 Per Kelasnya"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZwB8cxdRcktx"
      },
      "source": [
        "idx_sample = np.array([],dtype=int)\n",
        "\n",
        "for i in range(10):\n",
        "    idx = (y == i).reshape(x.shape[0])\n",
        "    idx_data = np.where(idx == True)\n",
        "    sampled_list = np.random.choice(idx_data[0], size=1000, replace=False)\n",
        "    idx_sample = np.concatenate((idx_sample, sampled_list), axis=0)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BdnYBQdXtl16"
      },
      "source": [
        "#### Melakukan Validasi Apakah Shape-nya Sudah Valid atau Belum"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_LteF08dnoP",
        "outputId": "fccd0e4b-9fa5-4a99-a645-ef36b9c6273a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "x_sample = x[idx_sample]\n",
        "y_sample = y[idx_sample]\n",
        "x_sample.shape, y_sample.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((10000, 32, 32, 3), (10000, 1))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D2EMwzQyvRWE"
      },
      "source": [
        "#### Melakukan Normalisasi untuk $x$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oyFNEK_pvVPA"
      },
      "source": [
        "def normalize(x):\n",
        "    return x / 255.0\n",
        "\n",
        "x_sample = normalize(x_sample)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2IeZh_cyu5tM"
      },
      "source": [
        "#### Merubah Menjadi Matrix Binary untuk $y$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWALf5B-vPM3"
      },
      "source": [
        "y_sample = tf.keras.utils.to_categorical(y_sample)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JPEUQiXyvjTT"
      },
      "source": [
        "#### Memecah Menjadi 60 : 40 ~ Train : Test"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q4zKyVvRvoJ4"
      },
      "source": [
        "x_train, x_test, y_train, y_test = train_test_split(x_sample, y_sample, test_size=0.4)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UupbLpNXtxff"
      },
      "source": [
        "#### Membangun Model Convolutional Neural Network"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OBc6Q_8ckvaL",
        "outputId": "c2376f43-0ef4-4445-f672-023337d75945",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "convolutional_layers = []\n",
        "## Convolutional Layers 25 map, 3 x 3, activation = relu\n",
        "convolutional_layers.append(Conv2D(25, kernel_size=(3, 3), activation=tf.nn.relu, padding='SAME', kernel_initializer=tf.keras.initializers.HeUniform()))\n",
        "\n",
        "## Pooling Layer 2 x 2\n",
        "convolutional_layers.append(MaxPooling2D(2,2))\n",
        "\n",
        "## Convolutional Layers 50 map, 3 x 3, activation = relu\n",
        "convolutional_layers.append(Conv2D(50, kernel_size=(3, 3), activation=tf.nn.relu, padding='SAME', kernel_initializer=tf.keras.initializers.HeUniform()))\n",
        "\n",
        "## Pooling Layer 2 x 2\n",
        "convolutional_layers.append(MaxPooling2D(2,2))\n",
        "\n",
        "## Convolutional Layers 100 map, 3 x 3, activation = relu\n",
        "convolutional_layers.append(Conv2D(100, kernel_size=(3, 3), activation=tf.nn.relu, padding='SAME', kernel_initializer=tf.keras.initializers.HeUniform()))\n",
        "\n",
        "## Pooling Layer 2 x 2\n",
        "convolutional_layers.append(MaxPooling2D(2,2))\n",
        "\n",
        "convolutional_layers.append(Flatten())\n",
        "\n",
        "## Hidden Layer 100 node\n",
        "convolutional_layers.append(Dense(100, activation=tf.nn.relu))\n",
        "\n",
        "## Output 10 class\n",
        "convolutional_layers.append(Dense(10, activation=tf.nn.softmax))\n",
        "\n",
        "## Menginisialisasi instance model\n",
        "convolutional_model = Sequential(convolutional_layers)\n",
        "\n",
        "## Membangun model\n",
        "convolutional_model.build(input_shape=x_train.shape)\n",
        "convolutional_model.output_shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(6000, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8bWlWHRhwRWZ"
      },
      "source": [
        "#### Melakukan Kompilasi ke dalam Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhGSXOhbveFo"
      },
      "source": [
        "convolutional_model.compile(\n",
        "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.01),\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=[\n",
        "      'accuracy',\n",
        "      recall,\n",
        "      specificity,\n",
        "      f1_score\n",
        "    ])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tbAYmxNOu70R"
      },
      "source": [
        "#### Melakukan _fitting_ dengan $\\text{epochs} = 100$, $\\text{batch_size} = 10$, dan $\\text{learning_rate} = 0.01$"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b0vPHzTdyB67",
        "outputId": "aff379e6-0d84-4535-e07b-fb14385442ee",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 411
        }
      },
      "source": [
        "convolutional_model_hist = convolutional_model.fit(x_train, y_train, epochs=100, batch_size=10, validation_data=(x_test, y_test), use_multiprocessing=True)"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "600/600 [==============================] - 15s 25ms/step - loss: 2.3432 - accuracy: 0.0940 - recall: 0.0000e+00 - specificity: 0.9996 - f1_score: 0.0000e+00 - val_loss: 2.3052 - val_accuracy: 0.0965 - val_recall: 0.0000e+00 - val_specificity: 1.0000 - val_f1_score: 0.0000e+00\n",
            "Epoch 2/100\n",
            "  4/600 [..............................] - ETA: 8s - loss: 2.3133 - accuracy: 0.0500 - recall: 0.0000e+00 - specificity: 1.0000 - f1_score: 0.0000e+00    "
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-00e47564e0f7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mconvolutional_model_hist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconvolutional_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    106\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    107\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 108\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    109\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    110\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1096\u001b[0m                 batch_size=batch_size):\n\u001b[1;32m   1097\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_train_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1098\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1099\u001b[0m               \u001b[0;32mif\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_sync\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m                 \u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masync_wait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    778\u001b[0m       \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    779\u001b[0m         \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 780\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    781\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    782\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    805\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    806\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 807\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    808\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    809\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2828\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2829\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2830\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2831\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1846\u001b[0m                            resource_variable_ops.BaseResourceVariable))],\n\u001b[1;32m   1847\u001b[0m         \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1848\u001b[0;31m         cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[1;32m   1849\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1850\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1922\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1923\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1924\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1925\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1926\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    548\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    549\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 550\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    551\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    552\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oeetNYtYv3ha"
      },
      "source": [
        "3. Lakukan skenario eksperimen untuk mendapatkan metrik evaluasi optimal ($\\text{akurasi}$, $\\text{sensitivity}$, $\\text{specifity}$, dan $f_{1} \\text{ score}$) dengan mengubah parameter yaitu:\n",
        "    1. Mengubah epoch, dengan $\\text{learning_rate} = 0.1$ dan $\\text\n",
        "{batch_number} = 10$.\n",
        "    2. Mengubah jumlah $\\text{batch number}$ dengan $\\text{epoch}$ optimal dari skenario (1) dan $\\text{learning_rate} = 0.1$.\n",
        "    3. Mengubah $\\text{learning_rate}$ dengan $\\text{epoch}$ optimal dari skenario (1) dan jumlah $\\text{batch_number}$ optimal dari skenario (2)."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hiRP7I5HvzrS"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}